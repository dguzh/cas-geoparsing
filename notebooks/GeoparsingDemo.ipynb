{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geoparsing Demo: Extracting Locations from Text\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the spatial search notebook, we worked with documents that already had geographic coordinates (the Geograph photos were geotagged by photographers). But what if we didn't have these coordinates? What if we only had the text descriptions?\n",
    "\n",
    "This notebook demonstrates **geoparsing** - the process of automatically:\n",
    "1. **Recognizing** place names in unstructured text\n",
    "2. **Resolving** them to geographic coordinates\n",
    "\n",
    "We'll use the [Irchel Geoparser](https://docs.geoparser.app/) library to extract locations from Geograph photo descriptions, then evaluate how accurately these extracted locations match the tagged photo coordinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the required libraries and load our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Geoparser imports\n",
    "from geoparser import Geoparser\n",
    "from geoparser.modules import SpacyRecognizer, SentenceTransformerResolver\n",
    "\n",
    "# For coordinate calculations\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Geograph Corpus\n",
    "\n",
    "We'll load the same dataset used in the spatial search notebook - geotagged photographs with text descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('./data')\n",
    "fn1 = data_folder / 'geograph_mini_corpus.csv'\n",
    "\n",
    "geograph = pd.read_csv(fn1, encoding='latin-1')\n",
    "\n",
    "# For this demo, we'll work with the longest texts (better context for geoparsing)\n",
    "# The Irchel Geoparser uses context to resolve toponyms, so longer texts generally work better\n",
    "sample_size = 100\n",
    "\n",
    "# Calculate text length and get the n longest texts\n",
    "geograph['text_length'] = geograph['text'].str.len()\n",
    "geograph_sorted = geograph.sort_values('text_length', ascending=False)\n",
    "\n",
    "# Select the n longest texts, then restore original order\n",
    "sample = geograph_sorted.head(sample_size).sort_index().reset_index(drop=True)\n",
    "sample = sample.drop(columns=['text_length'])  # Remove helper column\n",
    "\n",
    "print(f'Loaded {len(sample)} documents for geoparsing (longest texts for better context).')\n",
    "print(f'\\nExample document:')\n",
    "print(f\"\\nID: {sample.iloc[0]['id']}\")\n",
    "print(f\"\\nTitle: {sample.iloc[0]['title']}\")\n",
    "print(f\"\\nText: {sample.iloc[0]['text']}\")\n",
    "print(f\"\\nPhoto Location: ({sample.iloc[0]['lat']:.4f}, {sample.iloc[0]['lon']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Geoparser\n",
    "\n",
    "We'll configure the Irchel Geoparser with:\n",
    "- [SpacyRecognizer](https://docs.geoparser.app/en/latest/guides/modules.html#spacyrecognizer)\n",
    "- [SentenceTransformerResolver](https://docs.geoparser.app/en/latest/guides/modules.html#sentencetransformerresolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing geoparser components...\")\n",
    "\n",
    "# Initialize recognizer (identifies place names in text)\n",
    "recognizer = SpacyRecognizer()\n",
    "\n",
    "# Initialize resolver (links place names to coordinates)\n",
    "resolver = SentenceTransformerResolver(min_similarity=0.5)\n",
    "\n",
    "# Create geoparser instance\n",
    "geoparser = Geoparser(recognizer=recognizer, resolver=resolver)\n",
    "\n",
    "print(\"Geoparser ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Documents with Geoparser\n",
    "\n",
    "Now we'll process each document to extract place names and their coordinates. We'll combine the title and text for better context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare texts for geoparsing (combine title and text for better context)\n",
    "texts = []\n",
    "for idx, row in sample.iterrows():\n",
    "    title = str(row['title']) if pd.notna(row['title']) else \"\"\n",
    "    text = str(row['text']) if pd.notna(row['text']) else \"\"\n",
    "    combined = f\"{title}. {text}\".strip()\n",
    "    texts.append(combined)\n",
    "\n",
    "print(f\"Processing {len(texts)} documents...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Process all documents\n",
    "documents = geoparser.parse(texts)\n",
    "\n",
    "print(f\"\\nProcessed {len(documents)} documents!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Results\n",
    "\n",
    "Let's examine what the geoparser found. We'll extract all resolved toponyms for each document and calculate their distance from the true photo location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define haversine distance function first (we'll need it)\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees).\n",
    "    Returns distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    \n",
    "    # Radius of earth in kilometers\n",
    "    r = 6371\n",
    "    \n",
    "    return c * r\n",
    "\n",
    "# Store results with ALL toponyms for each document\n",
    "results = []\n",
    "\n",
    "for idx, doc in enumerate(documents):\n",
    "    doc_id = sample.iloc[idx]['id']\n",
    "    true_lat = sample.iloc[idx]['lat']\n",
    "    true_lon = sample.iloc[idx]['lon']\n",
    "    \n",
    "    # Get all resolved toponyms\n",
    "    toponyms = [t for t in doc.toponyms if t.location is not None]\n",
    "    \n",
    "    # Store each toponym with its details\n",
    "    toponyms_data = []\n",
    "    for toponym in toponyms:\n",
    "        location = toponym.location\n",
    "        topo_lat = location.data.get('latitude')\n",
    "        topo_lon = location.data.get('longitude')\n",
    "        \n",
    "        # Calculate distance from true location\n",
    "        distance = haversine_distance(true_lat, true_lon, topo_lat, topo_lon)\n",
    "        \n",
    "        toponyms_data.append({\n",
    "            'text': toponym.text,\n",
    "            'name': location.data.get('name'),\n",
    "            'lat': topo_lat,\n",
    "            'lon': topo_lon,\n",
    "            'country': location.data.get('country_name'),\n",
    "            'feature_class': location.data.get('feature_class'),\n",
    "            'feature_code': location.data.get('feature_code'),\n",
    "            'admin1': location.data.get('admin1_name'),\n",
    "            'admin2': location.data.get('admin2_name'),\n",
    "            'population': location.data.get('population', 0),\n",
    "            'distance_km': distance\n",
    "        })\n",
    "    \n",
    "    result = {\n",
    "        'doc_id': doc_id,\n",
    "        'true_lat': true_lat,\n",
    "        'true_lon': true_lon,\n",
    "        'text': texts[idx],\n",
    "        'num_toponyms': len(toponyms),\n",
    "        'toponyms': toponyms_data  # Store all toponym data\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "docs_with_toponyms = len(results_df[results_df['num_toponyms'] > 0])\n",
    "print(f\"Toponyms successfully resolved in {docs_with_toponyms} out of {len(results_df)} documents\")\n",
    "print(f\"Average toponyms per document: {results_df['num_toponyms'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Results\n",
    "\n",
    "Let's look at some examples to understand what the geoparser extracted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples with ALL resolved toponyms\n",
    "examples = results_df[results_df['num_toponyms'] > 0].sample(5)\n",
    "\n",
    "for idx, row in examples.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Document {row['doc_id']}:\")\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"\\nPhoto location: ({row['true_lat']:.4f}, {row['true_lon']:.4f})\")\n",
    "    print(f\"\\nExtracted toponyms ({len(row['toponyms'])}):\")\n",
    "    \n",
    "    for i, topo in enumerate(row['toponyms'], 1):\n",
    "        # Build location string\n",
    "        location_parts = [topo['name']]\n",
    "        if topo['admin2']:\n",
    "            location_parts.append(topo['admin2'])\n",
    "        if topo['admin1']:\n",
    "            location_parts.append(topo['admin1'])\n",
    "        if topo['country']:\n",
    "            location_parts.append(topo['country'])\n",
    "        \n",
    "        feature_info = f\" [{topo['feature_code']}]\" if topo['feature_code'] else \"\"\n",
    "        \n",
    "        print(f\"\\n  {i}. Toponym text: '{topo['text']}'\")\n",
    "        print(f\"     Resolved entity: {', '.join(location_parts)}{feature_info}\")\n",
    "        print(f\"     Resolved coordinates: ({topo['lat']:.4f}, {topo['lon']:.4f})\")\n",
    "        print(f\"     Distance from photo location: {topo['distance_km']:.2f} km\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Comparing Different Resolution Strategies\n",
    "\n",
    "Now we need to decide how to determine the predicted location for each document based on the extracted toponyms. We'll compare three different strategies:\n",
    "\n",
    "1. **First Mention**: Simply use the first toponym's location\n",
    "2. **Centroid**: Calculate the average (centroid) of all toponym locations\n",
    "3. **Domain-Specific Rule**: Use domain knowledge that our texts are about UK locations - select the first toponym that is in the UK\n",
    "\n",
    "Let's implement all three and compare their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: First Mention\n",
    "strategy1_errors = []\n",
    "for _, row in results_df[results_df['num_toponyms'] > 0].iterrows():\n",
    "    first_topo = row['toponyms'][0]\n",
    "    strategy1_errors.append(first_topo['distance_km'])\n",
    "\n",
    "# Strategy 2: Centroid\n",
    "strategy2_errors = []\n",
    "for _, row in results_df[results_df['num_toponyms'] > 0].iterrows():\n",
    "    if len(row['toponyms']) == 1:\n",
    "        # If only one toponym, same as first\n",
    "        strategy2_errors.append(row['toponyms'][0]['distance_km'])\n",
    "    else:\n",
    "        # Calculate centroid\n",
    "        avg_lat = np.mean([t['lat'] for t in row['toponyms']])\n",
    "        avg_lon = np.mean([t['lon'] for t in row['toponyms']])\n",
    "        error = haversine_distance(row['true_lat'], row['true_lon'], avg_lat, avg_lon)\n",
    "        strategy2_errors.append(error)\n",
    "\n",
    "# Strategy 3: Domain-Specific Rule\n",
    "# Use domain knowledge that texts are about UK locations\n",
    "strategy3_errors = []\n",
    "for _, row in results_df[results_df['num_toponyms'] > 0].iterrows():\n",
    "    # Try to find the first UK toponym\n",
    "    uk_toponym = None\n",
    "    for topo in row['toponyms']:\n",
    "        if topo['country'] == 'United Kingdom':\n",
    "            uk_toponym = topo\n",
    "            break\n",
    "    \n",
    "    # If we found a UK toponym, use it; otherwise fall back to first toponym\n",
    "    if uk_toponym is not None:\n",
    "        strategy3_errors.append(uk_toponym['distance_km'])\n",
    "    else:\n",
    "        # No UK toponym found, use first one\n",
    "        strategy3_errors.append(row['toponyms'][0]['distance_km'])\n",
    "\n",
    "print(f\"Calculated errors for {len(strategy1_errors)} documents using 3 strategies\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Strategy Performance\n",
    "\n",
    "Let's compute evaluation metrics for each of the three strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(errors, strategy_name):\n",
    "    \"\"\"Calculate and return evaluation metrics for a strategy\"\"\"\n",
    "    errors_array = np.array(errors)\n",
    "    \n",
    "    metrics = {\n",
    "        'strategy': strategy_name,\n",
    "        'mean': np.mean(errors_array),\n",
    "        'median': np.median(errors_array),\n",
    "        'std': np.std(errors_array),\n",
    "        'min': np.min(errors_array),\n",
    "        'max': np.max(errors_array),\n",
    "        'acc_1km': (errors_array <= 1).sum() / len(errors_array) * 100,\n",
    "        'acc_10km': (errors_array <= 10).sum() / len(errors_array) * 100,\n",
    "        'acc_161km': (errors_array <= 161).sum() / len(errors_array) * 100\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for all strategies\n",
    "metrics_s1 = calculate_metrics(strategy1_errors, \"Strategy 1: First Mention\")\n",
    "metrics_s2 = calculate_metrics(strategy2_errors, \"Strategy 2: Centroid\")\n",
    "metrics_s3 = calculate_metrics(strategy3_errors, \"Strategy 3: Domain-Specific Rule\")\n",
    "\n",
    "# Print comparison\n",
    "total_docs = len(results_df)\n",
    "docs_with_toponyms = len(strategy1_errors)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GEOPARSING EVALUATION: COMPARING RESOLUTION STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResolution Rate: {docs_with_toponyms}/{total_docs} ({docs_with_toponyms/total_docs*100:.1f}%)\")\n",
    "print(f\"Documents with at least one resolved toponym\\n\")\n",
    "\n",
    "for metrics in [metrics_s1, metrics_s2, metrics_s3]:\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"\\n{metrics['strategy']}\")\n",
    "    print(f\"\\nDistance Error Statistics (km):\")\n",
    "    print(f\"  Mean:   {metrics['mean']:7.2f} km\")\n",
    "    print(f\"  Median: {metrics['median']:7.2f} km\")\n",
    "    print(f\"  Std:    {metrics['std']:7.2f} km\")\n",
    "    print(f\"  Min:    {metrics['min']:7.2f} km\")\n",
    "    print(f\"  Max:    {metrics['max']:7.2f} km\")\n",
    "    print(f\"\\nAccuracy at Distance Thresholds:\")\n",
    "    print(f\"  Within 1 km:    {metrics['acc_1km']:5.1f}%\")\n",
    "    print(f\"  Within 10 km:   {metrics['acc_10km']:5.1f}%\")\n",
    "    print(f\"  Within 161 km:  {metrics['acc_161km']:5.1f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Store metrics for plotting\n",
    "all_metrics = [metrics_s1, metrics_s2, metrics_s3]\n",
    "all_errors = [strategy1_errors, strategy2_errors, strategy3_errors]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Error Distributions\n",
    "\n",
    "Let's visualize the error distributions for all three strategies side-by-side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(12, 14))\n",
    "\n",
    "strategy_names = ['First Mention', 'Centroid', 'Domain-Specific Rule']\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen']\n",
    "\n",
    "# Calculate common x and y axis limits for all plots\n",
    "all_errors_combined = strategy1_errors + strategy2_errors + strategy3_errors\n",
    "x_max = max(all_errors_combined)\n",
    "x_min = 0\n",
    "\n",
    "# Calculate histogram bins for all data to determine y limits\n",
    "hist_counts = []\n",
    "for errors in all_errors:\n",
    "    counts, _ = np.histogram(errors, bins=50, range=(x_min, x_max))\n",
    "    hist_counts.append(counts.max())\n",
    "y_max = max(hist_counts) * 1.1  # Add 10% padding\n",
    "\n",
    "for idx, (ax, errors, metrics, color, name) in enumerate(zip(axes, all_errors, all_metrics, colors, strategy_names)):\n",
    "    # Histogram of errors\n",
    "    ax.hist(errors, bins=50, range=(x_min, 1000), edgecolor='black', alpha=0.7, color=color)\n",
    "    ax.axvline(metrics['mean'], color='lightcoral', linestyle='--', linewidth=2, \n",
    "               label=f'Mean: {metrics[\"mean\"]:.1f} km')\n",
    "    ax.axvline(metrics['median'], color='mediumturquoise', linestyle='--', linewidth=2, \n",
    "               label=f'Median: {metrics[\"median\"]:.1f} km')\n",
    "    \n",
    "    # Set common axis limits\n",
    "    ax.set_xlim(x_min, 1000)\n",
    "    ax.set_ylim(0, y_max)\n",
    "    \n",
    "    ax.set_xlabel('Error Distance (km)', fontsize=11)\n",
    "    ax.set_ylabel('Number of Documents', fontsize=11)\n",
    "    ax.set_title(f'Strategy {idx+1}: {name}', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text box with key metrics\n",
    "    textstr = f'Acc@161km: {metrics[\"acc_161km\"]:.1f}%'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.97, 0.97, textstr, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='right', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Spatial Search\n",
    "\n",
    "In the spatial search notebook, we assumed all documents came with precise coordinates. This demo showed:\n",
    "\n",
    "- For datasets without coordinates, geoparsing can automatically generate them from text\n",
    "- Geoparsing gives us automation but we potentially lose some spatial precision\n",
    "- Single documents often mention multiple places - choosing the \"right\" one is non-trivial\n",
    "- Different applications may benefit from different resolution strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
