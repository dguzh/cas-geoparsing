{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mapping Texts: Visualizing Geographic References in Literature\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In the previous geoparsing notebook, we explored how to use geoparsing to **derive a single location** for entire documents - answering the question \"where is this document about?\" We compared different strategies for selecting the most representative location from multiple place mentions.\n",
        "\n",
        "In this notebook, we take a different approach. Instead of reducing multiple locations to one, we embrace the richness of geographic references throughout a text. Our goal is to **map the geographic landscape of literature** - to visualize all the places mentioned and see patterns in how they appear.\n",
        "\n",
        "This is particularly interesting for travel literature, where authors describe journeys through different places. We'll use the [Irchel Geoparser](https://docs.geoparser.app/) to extract and map locations from classic travel books, creating two types of visualizations:\n",
        "\n",
        "1. **Frequency Map**: Shows which places are mentioned most often\n",
        "2. **Journey Progression Map**: Shows the order in which places first appear in the narrative\n",
        "\n",
        "These visualizations can reveal narrative patterns, help readers understand geographic scope, and provide a new way to explore literary texts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the required libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import re\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# Geoparser imports\n",
        "from geoparser import Geoparser\n",
        "from geoparser.modules import SpacyRecognizer, SentenceTransformerResolver\n",
        "\n",
        "# Visualization imports\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select a Book\n",
        "\n",
        "We'll work with classic travel literature from Project Gutenberg. Choose one of these books (or experiment with all three!):\n",
        "\n",
        "1. **Jules Verne** - *Around the World in Eighty Days* (1873): Phileas Fogg's famous race around the globe\n",
        "2. **Mark Twain** - *The Innocents Abroad* (1869): A humorous account of American tourists in Europe and the Holy Land\n",
        "3. **William Makepeace Thackeray** - *Notes on a Journey from Cornhill to Grand Cairo* (1846): Travel sketches from London to Egypt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Book options\n",
        "BOOKS = {\n",
        "    'verne': {\n",
        "        'title': 'Around the World in Eighty Days',\n",
        "        'author': 'Jules Verne',\n",
        "        'url': 'https://www.gutenberg.org/files/103/103-0.txt'\n",
        "    },\n",
        "    'twain': {\n",
        "        'title': 'The Innocents Abroad',\n",
        "        'author': 'Mark Twain',\n",
        "        'url': 'https://www.gutenberg.org/files/3176/3176-0.txt'\n",
        "    },\n",
        "    'thackeray': {\n",
        "        'title': 'Notes on a Journey from Cornhill to Grand Cairo',\n",
        "        'author': 'William Makepeace Thackeray',\n",
        "        'url': 'https://www.gutenberg.org/files/1863/1863-0.txt'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Select book (change this to 'twain' or 'thackeray' to try other books)\n",
        "selected_book = 'verne'\n",
        "\n",
        "book_info = BOOKS[selected_book]\n",
        "print(f\"Selected: {book_info['title']} by {book_info['author']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download and Extract Chapters\n",
        "\n",
        "We'll download the book from Project Gutenberg and split it into chapters. Splitting by chapters is important because:\n",
        "1. It provides natural segmentation for the geoparser\n",
        "2. It allows us to track when locations first appear in the narrative\n",
        "3. It keeps individual text chunks manageable for processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download \"Around the World in Eighty Days\" from Project Gutenberg\n",
        "url = book_info['url']\n",
        "response = requests.get(url)\n",
        "full_text = response.text\n",
        "\n",
        "# End marker\n",
        "end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
        "end_idx = full_text.find(end_marker)\n",
        "if end_idx != -1:\n",
        "    full_text = full_text[:end_idx]\n",
        "\n",
        "# Split into chapters\n",
        "# Actual chapter headings: \"CHAPTER I.\" on their own line (no leading space)\n",
        "# TOC entries: \" CHAPTER I. IN WHICH...\" (leading space, description on same line)\n",
        "lines = full_text.split('\\n')\n",
        "chapter_positions = []\n",
        "current_pos = 0\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    stripped = line.rstrip()\n",
        "    # Match lines that are exactly \"CHAPTER [ROMAN].\" with no leading space\n",
        "    if re.match(r'CHAPTER [IVXLCDM]+\\b', stripped) and not line.startswith(' '):\n",
        "        chapter_positions.append(current_pos)\n",
        "    current_pos += len(line) + 1\n",
        "\n",
        "# Extract chapter texts\n",
        "chapter_texts = []\n",
        "for i in range(len(chapter_positions)):\n",
        "    if i < len(chapter_positions) - 1:\n",
        "        chapter_text = full_text[chapter_positions[i]:chapter_positions[i+1]].strip()\n",
        "    else:\n",
        "        chapter_text = full_text[chapter_positions[i]:].strip()\n",
        "    chapter_texts.append(chapter_text)\n",
        "\n",
        "print(f\"Downloaded book: {len(full_text):,} characters\")\n",
        "print(f\"Split into {len(chapter_texts)} chapters\")\n",
        "print(f\"\\nFirst chapter preview (first 200 characters):\")\n",
        "print(chapter_texts[0][:200] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the Geoparser\n",
        "\n",
        "We'll use the same geoparser configuration as in the previous notebook:\n",
        "- [SpacyRecognizer](https://docs.geoparser.app/en/latest/guides/modules.html#spacyrecognizer) for identifying place names\n",
        "- [SentenceTransformerResolver](https://docs.geoparser.app/en/latest/guides/modules.html#sentencetransformerresolver) for linking them to coordinates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Initializing geoparser components...\")\n",
        "\n",
        "# Initialize recognizer (identifies place names in text)\n",
        "recognizer = SpacyRecognizer(model_name=\"en_core_web_sm\")\n",
        "\n",
        "# Initialize resolver (links place names to coordinates)\n",
        "resolver = SentenceTransformerResolver(min_similarity=0.5)\n",
        "\n",
        "# Create geoparser instance\n",
        "geoparser = Geoparser(recognizer=recognizer, resolver=resolver)\n",
        "\n",
        "print(\"Geoparser ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Chapters with Geoparser\n",
        "\n",
        "Now we'll process each chapter to extract place names and their coordinates. We pass all chapters as a list to the geoparser, which processes them efficiently while keeping them separate so we can track which chapter each location appears in.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Processing {len(chapter_texts)} chapters...\")\n",
        "print(\"This may take several minutes depending on the book length...\\\\n\")\n",
        "\n",
        "# Process all chapters - pass as a list, not concatenated\n",
        "documents = geoparser.parse(chapter_texts)\n",
        "\n",
        "print(f\"\\\\nProcessed {len(documents)} chapters!\")\n",
        "\n",
        "# Quick summary\n",
        "total_toponyms = sum(len([t for t in doc.toponyms if t.location is not None]) for doc in documents)\n",
        "print(f\"Total resolved toponyms across all chapters: {total_toponyms}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract and Structure Toponym Data\n",
        "\n",
        "Now we'll extract all resolved toponyms from each chapter, keeping track of:\n",
        "- The location name and coordinates\n",
        "- Which chapter it appears in\n",
        "- How many times it's mentioned throughout the book\n",
        "\n",
        "We'll create a comprehensive dataset that we can use for both visualizations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract all toponyms with chapter information\n",
        "all_locations = []\n",
        "\n",
        "for chapter_idx, doc in enumerate(documents):\n",
        "    chapter_num = chapter_idx + 1  # 1-indexed for human readability\n",
        "    \n",
        "    # Get all resolved toponyms in this chapter\n",
        "    toponyms = [t for t in doc.toponyms if t.location is not None]\n",
        "    \n",
        "    for toponym in toponyms:\n",
        "        location = toponym.location\n",
        "        \n",
        "        # Create a unique identifier for each geographic location\n",
        "        # We use (name, lat, lon) to distinguish different places\n",
        "        location_data = {\n",
        "            'name': location.data.get('name'),\n",
        "            'lat': location.data.get('latitude'),\n",
        "            'lon': location.data.get('longitude'),\n",
        "            'country': location.data.get('country_name'),\n",
        "            'country_code': location.data.get('country_code'),\n",
        "            'feature_class': location.data.get('feature_class'),\n",
        "            'feature_code': location.data.get('feature_code'),\n",
        "            'chapter': chapter_num,\n",
        "            'toponym_text': toponym.text\n",
        "        }\n",
        "        \n",
        "        all_locations.append(location_data)\n",
        "\n",
        "# Create DataFrame\n",
        "locations_df = pd.DataFrame(all_locations)\n",
        "\n",
        "print(f\"Extracted {len(locations_df)} toponym mentions\")\n",
        "print(f\"Unique locations: {locations_df.groupby(['name', 'lat', 'lon']).ngroups}\")\n",
        "print(f\"\\\\nFirst few mentions:\")\n",
        "print(locations_df[['chapter', 'toponym_text', 'name', 'country']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Data for Visualization\n",
        "\n",
        "For our maps, we need to aggregate the data:\n",
        "1. **For the frequency map**: Count how many times each location appears\n",
        "2. **For the progression map**: Track the first chapter where each location appears\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by unique location (name + coordinates)\n",
        "# This handles cases where the same place might be referred to with slight variations\n",
        "location_groups = locations_df.groupby(['name', 'lat', 'lon']).agg({\n",
        "    'country': 'first',\n",
        "    'country_code': 'first',\n",
        "    'chapter': ['min', 'count']  # min = first mention, count = frequency\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "location_groups.columns = ['name', 'lat', 'lon', 'country', 'country_code', 'first_chapter', 'frequency']\n",
        "\n",
        "# Sort by first appearance\n",
        "location_groups = location_groups.sort_values('first_chapter')\n",
        "\n",
        "print(f\"Unique locations: {len(location_groups)}\")\n",
        "print(f\"\\\\nMost frequently mentioned locations:\")\n",
        "print(location_groups.nlargest(10, 'frequency')[['name', 'country', 'frequency', 'first_chapter']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Map 1: Frequency-Based Visualization\n",
        "\n",
        "This map shows **which places are mentioned most often** in the book. The size of each marker corresponds to how many times that location appears. This helps us understand which places are most important to the narrative.\n",
        "\n",
        "**Interactive features:**\n",
        "- Hover over markers to see location name, country code, and frequency count\n",
        "- Zoom and pan to explore different regions\n",
        "- Transparent markers allow you to see overlapping locations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create hover text\n",
        "location_groups['hover_text'] = (\n",
        "    '<b>' + location_groups['name'] + '</b><br>' +\n",
        "    'Country: ' + location_groups['country_code'].fillna('Unknown') + '<br>' +\n",
        "    'Mentions: ' + location_groups['frequency'].astype(str)\n",
        ")\n",
        "\n",
        "# Create the frequency map\n",
        "fig1 = go.Figure()\n",
        "\n",
        "fig1.add_trace(go.Scattergeo(\n",
        "    lon=location_groups['lon'],\n",
        "    lat=location_groups['lat'],\n",
        "    text=location_groups['hover_text'],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=location_groups['frequency'],\n",
        "        sizemode='diameter',\n",
        "        sizeref=location_groups['frequency'].max() / 40,  # Scale factor for visibility\n",
        "        sizemin=4,\n",
        "        color='steelblue',\n",
        "        opacity=0.6,\n",
        "        line=dict(width=0.5, color='white')\n",
        "    ),\n",
        "    hovertemplate='%{text}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig1.update_layout(\n",
        "    title=dict(\n",
        "        text=f'Location Frequency Map: {book_info[\"title\"]}<br><sub>Marker size indicates number of mentions</sub>',\n",
        "        x=0.5,\n",
        "        xanchor='center'\n",
        "    ),\n",
        "    geo=dict(\n",
        "        projection_type='natural earth',\n",
        "        showland=True,\n",
        "        landcolor='rgb(243, 243, 243)',\n",
        "        coastlinecolor='rgb(204, 204, 204)',\n",
        "        showlakes=True,\n",
        "        lakecolor='rgb(220, 230, 240)',\n",
        "        showcountries=True,\n",
        "        countrycolor='rgb(204, 204, 204)'\n",
        "    ),\n",
        "    height=600,\n",
        "    margin=dict(l=0, r=0, t=80, b=0)\n",
        ")\n",
        "\n",
        "fig1.show()\n",
        "\n",
        "print(f\"\\\\nMap shows {len(location_groups)} unique locations\")\n",
        "print(f\"Total mentions: {location_groups['frequency'].sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Map 2: Journey Progression Visualization\n",
        "\n",
        "This map shows **when places first appear** in the narrative. The color of each marker represents the chapter number where that location is first mentioned, creating a visual representation of the journey's progression through the book.\n",
        "\n",
        "**Interactive features:**\n",
        "- Hover over markers to see location name, country code, and first mention chapter\n",
        "- Colors follow a gradient from early chapters (purple/blue) to later chapters (yellow/red)\n",
        "- All markers are the same size to focus on temporal sequence rather than frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create hover text for progression map\n",
        "location_groups['hover_text_progression'] = (\n",
        "    '<b>' + location_groups['name'] + '</b><br>' +\n",
        "    'Country: ' + location_groups['country_code'].fillna('Unknown') + '<br>' +\n",
        "    'First mentioned in Chapter: ' + location_groups['first_chapter'].astype(str)\n",
        ")\n",
        "\n",
        "# Create the progression map\n",
        "fig2 = go.Figure()\n",
        "\n",
        "fig2.add_trace(go.Scattergeo(\n",
        "    lon=location_groups['lon'],\n",
        "    lat=location_groups['lat'],\n",
        "    text=location_groups['hover_text_progression'],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=12,  # Fixed size for all markers\n",
        "        color=location_groups['first_chapter'],\n",
        "        colorscale='deep',  # Gradient colorscale that goes through spectrum\n",
        "        cmin=location_groups['first_chapter'].min(),\n",
        "        cmax=location_groups['first_chapter'].max(),\n",
        "        showscale=False,  # Hide the colorbar - chapter info available in hover\n",
        "        opacity=0.8,\n",
        "        line=dict(width=0.5, color='white')\n",
        "    ),\n",
        "    hovertemplate='%{text}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig2.update_layout(\n",
        "    title=dict(\n",
        "        text=f'Journey Progression Map: {book_info[\"title\"]}<br><sub>Color indicates chapter of first mention</sub>',\n",
        "        x=0.5,\n",
        "        xanchor='center'\n",
        "    ),\n",
        "    geo=dict(\n",
        "        projection_type='natural earth',\n",
        "        showland=True,\n",
        "        landcolor='rgb(243, 243, 243)',\n",
        "        coastlinecolor='rgb(204, 204, 204)',\n",
        "        showlakes=True,\n",
        "        lakecolor='rgb(220, 230, 240)',\n",
        "        showcountries=True,\n",
        "        countrycolor='rgb(204, 204, 204)'\n",
        "    ),\n",
        "    height=600,\n",
        "    margin=dict(l=0, r=0, t=80, b=0)\n",
        ")\n",
        "\n",
        "fig2.show()\n",
        "\n",
        "print(f\"\\\\nMap shows progression from Chapter {location_groups['first_chapter'].min()} to Chapter {location_groups['first_chapter'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion: From Document Geolocation to Text Mapping\n",
        "\n",
        "This notebook demonstrates a different application of geoparsing compared to the previous notebook:\n",
        "\n",
        "### Previous Notebook: Document Geolocation\n",
        "- **Goal**: Derive a single location for each document\n",
        "- **Challenge**: Choose the \"best\" location from multiple mentions\n",
        "- **Use case**: Spatial search, filtering documents by location\n",
        "- **Strategy**: We compared first mention, centroid, and domain-specific rules\n",
        "\n",
        "### This Notebook: Text Mapping\n",
        "- **Goal**: Visualize all geographic references in a text\n",
        "- **Challenge**: Present multiple locations meaningfully\n",
        "- **Use case**: Understanding geographic scope, exploring narrative journeys, analyzing travel literature\n",
        "- **Strategy**: We created frequency and progression visualizations\n",
        "\n",
        "### Key Insights\n",
        "\n",
        "1. **Same technology, different applications**: The geoparser extracts the same information, but we use it differently depending on our goals\n",
        "\n",
        "2. **Visualization reveals patterns**: The maps show not just where places are, but how authors structure their narratives geographically\n",
        "\n",
        "3. **Multiple perspectives matter**: The frequency map and progression map tell different stories about the same text\n",
        "\n",
        "4. **Literature as geographic data**: Travel literature, historical documents, and narratives become explorable through a spatial lens\n",
        "\n",
        "### Try It Yourself\n",
        "\n",
        "Change the `selected_book` variable at the top to explore different books and see how their geographic patterns differ!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
